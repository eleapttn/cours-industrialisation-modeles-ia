{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 - Entraînement, exportation d'un CNN et versioning\n",
    "\n",
    "L'objectif de ce TP est de développer, entraîner et exporter un modèle de type CNN en utilisant le dataset cats VS dogs pour la classification d'images.\n",
    "\n",
    "1. Donnez les informations quant au.x GPU.s utilisé.s (nombre, type, mémoire dédiée)\n",
    "2. Renseignez la version de Python utilisée\n",
    "3. Chargez le dataset cats_vs_dogs avec TensorFlow\n",
    "4. Séparez le dataset de la manière suivante :\n",
    "5. Implémentez un modèle de classification d'images avec Tensorflow\n",
    "6. Entraînez le modèle en utilisant la puissance du GPU\n",
    "7. Testez le modèle sur le dataset de test\n",
    "8. Sauvegardez le modèle au format ONNX\n",
    "9. Chargez-le pour effectuer une prédiction sur une image\n",
    "10. Créez un fichier requirements.txt avec toutes les dépendances installées et leur version\n",
    "\n",
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow[and-cuda] --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Informations sur le GPU et la version de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 12 21:08:57 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100S-PCIE-32GB          On  |   00000000:00:06.0 Off |                    0 |\n",
      "| N/A   33C    P0             25W /  250W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chargement du dataset Cats vs Dogs depuis TensorFlow Datasets\n",
    "\n",
    "Accéder au dataset : https://www.tensorflow.org/datasets/catalog/cats_vs_dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('cats_vs_dogs', as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : {'train': <_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset :\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info : tfds.core.DatasetInfo(\n",
      "    name='cats_vs_dogs',\n",
      "    full_name='cats_vs_dogs/4.0.1',\n",
      "    description=\"\"\"\n",
      "    A large set of images of cats and dogs. There are 1738 corrupted images that are dropped.\n",
      "    \"\"\",\n",
      "    homepage='https://www.microsoft.com/en-us/download/details.aspx?id=54765',\n",
      "    data_dir='/workspace/tensorflow_datasets/cats_vs_dogs/4.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=1.04 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
      "        'image/filename': Text(shape=(), dtype=string),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=23262, num_shards=16>,\n",
      "    },\n",
      "    citation=\"\"\"@Inproceedings (Conference){asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization,\n",
      "    author = {Elson, Jeremy and Douceur, John (JD) and Howell, Jon and Saul, Jared},\n",
      "    title = {Asirra: A CAPTCHA that Exploits Interest-Aligned Manual Image Categorization},\n",
      "    booktitle = {Proceedings of 14th ACM Conference on Computer and Communications Security (CCS)},\n",
      "    year = {2007},\n",
      "    month = {October},\n",
      "    publisher = {Association for Computing Machinery, Inc.},\n",
      "    url = {https://www.microsoft.com/en-us/research/publication/asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization/},\n",
      "    edition = {Proceedings of 14th ACM Conference on Computer and Communications Security (CCS)},\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Info :\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Séparation en 70% entraînement, 20% validation, 10% test\n",
    "\n",
    "- 70 % - training set\n",
    "- 20% - validation set\n",
    "- 10% - test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size : 23262\n"
     ]
    }
   ],
   "source": [
    "total_size = info.splits['train'].num_examples\n",
    "print(\"Total Size :\", total_size)\n",
    "\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.2 * total_size)\n",
    "test_size = total_size - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train'].take(train_size)\n",
    "val_data = dataset['train'].skip(train_size).take(val_size)\n",
    "test_data = dataset['train'].skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size : 16283 \n",
      "Validation Size : 4652 \n",
      "Test Size : 2327\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Size :\", train_size, \\\n",
    "      \"\\nValidation Size :\", val_size, \\\n",
    "      \"\\nTest Size :\", test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prétraitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement des images\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (128, 128)) / 255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(preprocess).batch(32).shuffle(1000)\n",
    "val_data = val_data.map(preprocess).batch(32)\n",
    "test_data = test_data.map(preprocess).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implémentez un modèle de classification d'images avec Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Entraînez le modèle en utilisant la puissance du GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m475/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6889 - loss: 0.5860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 21:10:01.173365: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[27,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[27,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-12 21:10:01.206737: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[27,64,61,61]{3,2,1,0}, u8[0]{0}) custom-call(f32[27,32,63,63]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m507/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6905 - loss: 0.5845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 21:10:06.229645: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-12 21:10:06.265430: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,61,61]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,63,63]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-12 21:10:07.870584: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[12,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-12 21:10:07.899499: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[12,64,61,61]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,32,63,63]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.6907 - loss: 0.5844 - val_accuracy: 0.7377 - val_loss: 0.5270\n",
      "Epoch 2/3\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.7810 - loss: 0.4686 - val_accuracy: 0.7752 - val_loss: 0.4800\n",
      "Epoch 3/3\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8352 - loss: 0.3658 - val_accuracy: 0.7758 - val_loss: 0.4757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ffb29ffafd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, epochs=3, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Testez le modèle sur le dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7806 - loss: 0.4630\n",
      "Test Accuracy: 77.52%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Sauvegarde du modèle au format ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install onnx onnxruntime-gpu tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tf2onnx\n",
    "import numpy as np\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739394664.361461   47421 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "I0000 00:00:1739394664.361671   47421 single_machine.cc:361] Starting new session\n",
      "I0000 00:00:1739394664.363023   47421 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:00:06.0, compute capability: 7.0\n",
      "I0000 00:00:1739394665.241056   47421 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:00:06.0, compute capability: 7.0\n",
      "I0000 00:00:1739394665.375544   47421 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "I0000 00:00:1739394665.375764   47421 single_machine.cc:361] Starting new session\n",
      "I0000 00:00:1739394665.377069   47421 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:00:06.0, compute capability: 7.0\n",
      "ERROR:tf2onnx.tfonnx:rewriter <function rewrite_constant_fold at 0x7ff968715d00>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé sous model.onnx\n"
     ]
    }
   ],
   "source": [
    "model.output_names=['output']\n",
    "\n",
    "onnx_model_path = \"model.onnx\"\n",
    "spec = (tf.TensorSpec((None, 128, 128, 3), tf.float32),)\n",
    "onxx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=18)\n",
    "onnx.save_model(onxx_model, onnx_model_path)\n",
    "print(f\"Modèle sauvegardé sous {onnx_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Chargement du modèle ONNX et prédiction sur une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction ONNX: [array([[0.8292207]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "onnx_model_path = \"model.onnx\"\n",
    "session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "image_path = \"/workspace/dog.jpeg\"\n",
    "image = Image.open(image_path).resize((128, 128))\n",
    "image = np.array(image, dtype=np.float32) / 255.0\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "prediction = session.run([output_name], {input_name: image})\n",
    "print(\"Prédiction ONNX:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Créez un fichier requirements.txt avec toutes les dépendances installées et leur version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow-datasets==4.9.7\n",
    "tensorflow[and-cuda]==2.18.0\n",
    "numpy==2.0.2\n",
    "onnx==1.17.0\n",
    "onnxruntime-gpu==1.20.1\n",
    "pillow==11.1.0\n",
    "tf2onnx==1.16.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
